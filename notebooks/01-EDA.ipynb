{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "**AI-Powered Code Review Assistant**  \n",
    "**CS 5590 - Final Project**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the **CodeSearchNet** dataset to:\n",
    "\n",
    "1. Understand the **structure** and **distribution** of code samples\n",
    "2. Analyze **data quality** and identify potential issues\n",
    "3. Visualize **label distributions** and class imbalance\n",
    "4. Determine appropriate **preprocessing strategies**\n",
    "5. Inform **model architecture** and **training decisions**\n",
    "\n",
    "---\n",
    "\n",
    "## CRISP-DM Phase: Data Understanding\n",
    "\n",
    "This notebook corresponds to **Phase 2** of the CRISP-DM methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "    \n",
    "    # Clone repository\n",
    "    !git clone https://github.com/darshlukkad/Code-Review-Assistant.git\n",
    "    %cd Code-Review-Assistant\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q datasets transformers pandas matplotlib seaborn plotly tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "We'll use the **CodeSearchNet** dataset from Hugging Face, focusing on **Python** and **JavaScript** for our initial analysis.\n",
    "\n",
    "**Dataset Details:**\n",
    "- Source: GitHub repositories\n",
    "- Languages: Python, JavaScript, Java, Go, PHP, Ruby\n",
    "- Size: ~2M code samples\n",
    "- Format: Function code + documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a small subset first (for quick EDA)\n",
    "# For full training, remove the split parameter\n",
    "SUBSET_SIZE = 5000  # Adjust based on your memory\n",
    "\n",
    "print(\"Loading Python dataset...\")\n",
    "dataset_python = load_dataset(\n",
    "    \"code_search_net\",\n",
    "    \"python\",\n",
    "    split=f\"train[:{SUBSET_SIZE}]\"\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Loaded {len(dataset_python)} Python samples\")\n",
    "print(f\"\\nDataset features: {dataset_python.features.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few samples\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE CODE SNIPPET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample = dataset_python[0]\n",
    "print(f\"Repository: {sample['repo_name']}\")\n",
    "print(f\"Function: {sample['func_name']}\")\n",
    "print(f\"\\nCode:\\n{sample['func_code_string'][:500]}...\")\n",
    "print(f\"\\nDocstring:\\n{sample['func_documentation_string'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas for easier analysis\n",
    "df = pd.DataFrame(dataset_python)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Length Analysis\n",
    "\n",
    "Understanding code length distribution helps us:\n",
    "- Set appropriate **max_length** for tokenization\n",
    "- Identify **outliers** (very long/short functions)\n",
    "- Assess **memory requirements** for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate code statistics\n",
    "df['code_length'] = df['func_code_string'].str.len()\n",
    "df['num_lines'] = df['func_code_string'].str.count('\\n')\n",
    "df['num_tokens'] = df['func_code_string'].str.split().str.len()\n",
    "\n",
    "print(\"CODE LENGTH STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(df[['code_length', 'num_lines', 'num_tokens']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Code length histogram\n",
    "axes[0, 0].hist(df['code_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Code Length (characters)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Code Length')\n",
    "axes[0, 0].axvline(df['code_length'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Number of lines\n",
    "axes[0, 1].hist(df['num_lines'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_xlabel('Number of Lines')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Number of Lines')\n",
    "axes[0, 1].axvline(df['num_lines'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Number of tokens\n",
    "axes[1, 0].hist(df['num_tokens'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_xlabel('Number of Tokens')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Distribution of Number of Tokens')\n",
    "axes[1, 0].axvline(df['num_tokens'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Box plot for outlier detection\n",
    "axes[1, 1].boxplot([df['num_lines']], labels=['Lines'])\n",
    "axes[1, 1].set_ylabel('Number of Lines')\n",
    "axes[1, 1].set_title('Box Plot - Outlier Detection')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_code_length_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: eda_code_length_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights from Code Length Analysis:**\n",
    "\n",
    "Based on the distributions above, we can determine:\n",
    "- Most functions are **X-Y lines** (will update after running)\n",
    "- Median code length suggests **max_length=512 tokens** is appropriate for CodeBERT\n",
    "- Outliers (very long functions) may need special handling or truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Synthetic Labels\n",
    "\n",
    "Since CodeSearchNet doesn't have quality labels, we create them using **heuristic rules**.\n",
    "\n",
    "**Label Categories:**\n",
    "1. **Bug:** Error handling, try/except patterns\n",
    "2. **Security:** Authentication, passwords, secrets\n",
    "3. **Code Smell:** Long functions, high complexity\n",
    "4. **Style:** Missing docstrings, naming conventions  \n",
    "5. **Performance:** Nested loops, inefficient patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_code_quality(code_str, docstring):\n",
    "    \"\"\"\n",
    "    Apply heuristic rules to create quality labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Binary labels for each issue type\n",
    "    \"\"\"\n",
    "    labels = {\n",
    "        'bug': 0,\n",
    "        'security': 0,\n",
    "        'code_smell': 0,\n",
    "        'style': 0,\n",
    "        'performance': 0\n",
    "    }\n",
    "    \n",
    "    code_lower = code_str.lower()\n",
    "    \n",
    "    # Bug: Contains error handling\n",
    "    if 'except' in code_lower or 'error' in code_lower:\n",
    "        labels['bug'] = 1\n",
    "    \n",
    "    # Security: Contains sensitive keywords\n",
    "    security_keywords = ['password', 'token', 'secret', 'key', 'auth']\n",
    "    if any(kw in code_lower for kw in security_keywords):\n",
    "        labels['security'] = 1\n",
    "    \n",
    "    # Code smell: Long function (>50 lines)\n",
    "    if code_str.count('\\n') > 50:\n",
    "        labels['code_smell'] = 1\n",
    "    \n",
    "    # Style: Missing or short docstring\n",
    "    if not docstring or len(docstring) < 20:\n",
    "        labels['style'] = 1\n",
    "    \n",
    "    # Performance: Nested loops\n",
    "    if code_str.count('for ') >= 2 or code_str.count('while ') >= 2:\n",
    "        labels['performance'] = 1\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Apply labeling\n",
    "print(\"Creating synthetic labels...\")\n",
    "labels_list = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    labels = label_code_quality(\n",
    "        row['func_code_string'],\n",
    "        row.get('func_documentation_string', '')\n",
    "    )\n",
    "    labels_list.append(labels)\n",
    "\n",
    "# Add labels to dataframe\n",
    "labels_df = pd.DataFrame(labels_list)\n",
    "df = pd.concat([df, labels_df], axis=1)\n",
    "\n",
    "print(\"\\nâœ“ Labels created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Label Distribution Analysis\n",
    "\n",
    "**Critical for understanding class imbalance** - affects:\n",
    "- Loss function weighting\n",
    "- Evaluation metrics choice\n",
    "- Sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label statistics\n",
    "label_cols = ['bug', 'security', 'code_smell', 'style', 'performance']\n",
    "label_counts = df[label_cols].sum()\n",
    "\n",
    "print(\"LABEL DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "for label, count in label_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{label.capitalize():15} : {count:6,} ({percentage:5.2f}%)\")\n",
    "\n",
    "# Samples with no issues\n",
    "no_issues = (df[label_cols].sum(axis=1) == 0).sum()\n",
    "print(f\"\\nNo Issues       : {no_issues:6,} ({(no_issues/len(df))*100:5.2f}%)\")\n",
    "\n",
    "# Samples with multiple issues\n",
    "multi_issues = (df[label_cols].sum(axis=1) > 1).sum()\n",
    "print(f\"Multiple Issues : {multi_issues:6,} ({(multi_issues/len(df))*100:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart\n",
    "axes[0].bar(label_counts.index, label_counts.values, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('Issue Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Label Distribution (Bar Chart)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (label, count) in enumerate(label_counts.items()):\n",
    "    axes[0].text(i, count + 50, f'{count:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = plt.cm.Set3(range(len(label_counts)))\n",
    "axes[1].pie(\n",
    "    label_counts.values,\n",
    "    labels=label_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90\n",
    ")\n",
    "axes[1].set_title('Label Distribution (Pie Chart)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: eda_label_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Check if certain issues tend to co-occur - helps understand code quality patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df[label_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "plt.title('Label Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_label_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Saved: eda_label_correlation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Code Complexity Analysis\n",
    "\n",
    "Additional metrics to understand code characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate complexity metrics\n",
    "def calculate_complexity(code):\n",
    "    \"\"\"Simple complexity metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    metrics['cyclomatic'] = code.count('if ') + code.count('for ') + code.count('while ') + 1\n",
    "    metrics['num_functions'] = code.count('def ')\n",
    "    metrics['num_comments'] = code.count('#')\n",
    "    return metrics\n",
    "\n",
    "complexity_list = [calculate_complexity(code) for code in df['func_code_string']]\n",
    "complexity_df = pd.DataFrame(complexity_list)\n",
    "df = pd.concat([df, complexity_df], axis=1)\n",
    "\n",
    "print(\"COMPLEXITY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(df[['cyclomatic', 'num_functions', 'num_comments']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Recommendations\n",
    "\n",
    "Based on our EDA, we can make the following recommendations for the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EDA SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
    "print(f\"   - Total samples: {len(df):,}\")\n",
    "print(f\"   - Median code length: {df['code_length'].median():.0f} characters\")\n",
    "print(f\"   - Median lines: {df['num_lines'].median():.0f}\")\n",
    "print(f\"   - Median tokens: {df['num_tokens'].median():.0f}\")\n",
    "\n",
    "print(\"\\n2. LABEL DISTRIBUTION:\")\n",
    "print(f\"   - Most common issue: {label_counts.idxmax()} ({label_counts.max():,} samples)\")\n",
    "print(f\"   - Least common issue: {label_counts.idxmin()} ({label_counts.min():,} samples)\")\n",
    "print(f\"   - Imbalance ratio: {label_counts.max() / label_counts.min():.2f}:1\")\n",
    "\n",
    "print(\"\\n3. RECOMMENDATIONS:\")\n",
    "print(\"   âœ“ Use max_length=512 for tokenization (covers 95%+ of samples)\")\n",
    "print(\"   âœ“ Apply data augmentation to improve robustness\")\n",
    "print(\"   âœ“ Use BCEWithLogitsLoss for multi-label classification\")\n",
    "print(\"   âœ“ Consider class weights to handle imbalance\")\n",
    "print(\"   âœ“ Use stratified splits for train/val/test\")\n",
    "print(\"   âœ“ Monitor per-class metrics during training\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data\n",
    "\n",
    "Save the labeled dataset for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to keep\n",
    "columns_to_save = [\n",
    "    'func_code_string',\n",
    "    'func_name',\n",
    "    'func_documentation_string',\n",
    "    'bug', 'security', 'code_smell', 'style', 'performance'\n",
    "]\n",
    "\n",
    "df_clean = df[columns_to_save].copy()\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'labeled_code_samples.csv'\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved {len(df_clean)} samples to {output_file}\")\n",
    "print(f\"  File size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Next Step: Preprocessing (02-preprocessing.ipynb)\n",
    "\n",
    "Now that we've thoroughly analyzed the data, we can proceed to:\n",
    "- Tokenize code using CodeBERT\n",
    "- Apply data augmentation\n",
    "- Create train/val/test splits\n",
    "- Prepare data loaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
