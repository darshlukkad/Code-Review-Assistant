# AI-Powered Code Review Assistant

## ðŸŽ¯ Project Overview

An intelligent code review system powered by deep learning that automatically detects bugs, code smells, security vulnerabilities, and suggests improvements. Built as an end-to-end full-stack application for the CS 5590 AI/ML Final Project.

### Team Members
- Member 1: Data Engineering & Preprocessing
- Member 2: Model Development & Training
- Member 3: Full-Stack Application Development
- Member 4: Deployment & Documentation

### Key Features
âœ… Multi-label code issue detection (bugs, security, code smells, style)  
âœ… Support for Python and JavaScript  
âœ… Real-time inference with <2s response time  
âœ… Confidence scores and explainability  
âœ… Production-ready web application  
âœ… Comprehensive evaluation with TensorBoard  

---

## ðŸ“Š Project Methodology: CRISP-DM

This project follows the **CRISP-DM** (Cross-Industry Standard Process for Data Mining) methodology:

1. **Business Understanding:** Define code quality objectives and success criteria
2. **Data Understanding:** Explore CodeSearchNet and GitHub quality datasets
3. **Data Preparation:** Preprocessing, augmentation, and dataset splitting
4. **Modeling:** Fine-tune CodeBERT and compare architectures
5. **Evaluation:** Comprehensive metrics, ablation studies, visualization
6. **Deployment:** Full-stack web app with Docker and cloud deployment

See [CRISP-DM.md](docs/CRISP-DM.md) for detailed methodology documentation.

---

## ðŸš€ Quick Start

### Prerequisites
- Python 3.9+
- CUDA-capable GPU (recommended) or Google Colab
- Docker (for deployment)

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/code-review-assistant.git
cd code-review-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download pre-trained model (if available)
python src/deployment/download_model.py
```

### Running the Application

#### Option 1: Streamlit App (Recommended)
```bash
cd app/frontend
streamlit run app.py
```
Access at: http://localhost:8501

#### Option 2: Full Stack with FastAPI Backend
```bash
# Terminal 1: Start backend
cd app/backend
uvicorn main:app --reload --port 8000

# Terminal 2: Start frontend
cd app/frontend
streamlit run app.py
```

#### Option 3: Docker Deployment
```bash
docker-compose up --build
```
Access at: http://localhost:8501

---

## ðŸ“š Project Structure

```
code-review-assistant/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ 01-EDA.ipynb                  # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02-preprocessing.ipynb        # Data preprocessing
â”‚   â”œâ”€â”€ 03-model-training.ipynb       # Model training & tuning
â”‚   â””â”€â”€ 04-evaluation.ipynb           # Evaluation & visualization
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_loader.py            # Dataset loading utilities
â”‚   â”‚   â””â”€â”€ preprocessing.py          # Preprocessing functions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.py                  # Model architectures
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py                # Training loop
â”‚   â”‚   â””â”€â”€ config.py                 # Hyperparameter config
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ evaluator.py              # Evaluation metrics
â”‚   â”‚   â””â”€â”€ visualizations.py         # Plotting utilities
â”‚   â””â”€â”€ deployment/
â”‚       â””â”€â”€ inference.py              # Model inference
â”‚
â”œâ”€â”€ app/                               # Full-stack application
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ main.py                   # FastAPI server
â”‚   â”‚   â””â”€â”€ requirements.txt          # Backend dependencies
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ app.py                    # Streamlit UI
â”‚       â””â”€â”€ requirements.txt          # Frontend dependencies
â”‚
â”œâ”€â”€ deployment/                        # Deployment configs
â”‚   â”œâ”€â”€ Dockerfile                    # Docker container
â”‚   â”œâ”€â”€ docker-compose.yml            # Multi-container setup
â”‚   â”œâ”€â”€ kubernetes/                   # K8s manifests
â”‚   â””â”€â”€ cloud/                        # Cloud deployment scripts
â”‚
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ CRISP-DM.md                   # Methodology details
â”‚   â”œâ”€â”€ METHODOLOGY.md                # Process documentation
â”‚   â””â”€â”€ EVALUATION.md                 # Metrics & results
â”‚
â”œâ”€â”€ presentation/                      # Final deliverables
â”‚   â”œâ”€â”€ slides.pptx                   # Presentation deck
â”‚   â””â”€â”€ demo-video.mp4                # 5-15 min demo video
â”‚
â””â”€â”€ tests/                             # Test suite
    â”œâ”€â”€ test_data_loader.py
    â”œâ”€â”€ test_model.py
    â””â”€â”€ test_api.py
```

---

## ðŸ”¬ Model Architecture

### Base Model: CodeBERT
- Pre-trained on 6 programming languages
- 12 transformer layers, 768 hidden dimensions
- Fine-tuned for multi-label classification

### Training Details
- **Loss Function:** Binary Cross-Entropy (multi-label)
- **Optimizer:** AdamW (lr=2e-5, weight_decay=0.01)
- **Activation:** GELU (hidden), Sigmoid (output)
- **Batch Size:** 32
- **Epochs:** 10-15 with early stopping

See [notebooks/03-model-training.ipynb](notebooks/03-model-training.ipynb) for full implementation.

---

## ðŸ“ˆ Evaluation Metrics

### Model Performance
- **F1-Score:** Target â‰¥0.85 (macro-averaged)
- **Precision/Recall:** Per-class metrics
- **AUC-ROC:** Area under ROC curve
- **Inference Time:** <2 seconds per file

### Visualizations (20% of Project)
- Training/validation loss curves
- Confusion matrices per issue type
- ROC and Precision-Recall curves
- Ablation study comparisons
- TensorBoard dashboards

See [notebooks/04-evaluation.ipynb](notebooks/04-evaluation.ipynb) and [docs/EVALUATION.md](docs/EVALUATION.md).

---

## ðŸ§ª Ablation Studies

| Experiment | Description | F1-Score | Inference Time |
|------------|-------------|----------|----------------|
| Baseline | CodeBERT default | TBD | TBD |
| No Augmentation | Without data augmentation | TBD | TBD |
| GraphCodeBERT | Alternative architecture | TBD | TBD |
| DistilCodeBERT | Smaller, faster model | TBD | TBD |
| Focal Loss | Different loss function | TBD | TBD |

---

## ðŸŒ Deployment

### Local Development
```bash
streamlit run app/frontend/app.py
```

### Docker
```bash
docker-compose up --build
```

### Cloud (AWS/GCP/Azure)
```bash
cd deployment/cloud
./deploy.sh
```

See [deployment/README.md](deployment/README.md) for detailed instructions.

---

## ðŸ“Š Datasets

### Primary: CodeSearchNet
- **Source:** https://github.com/github/CodeSearchNet
- **Size:** ~2M code samples
- **Languages:** Python, Java, Go, PHP, JavaScript, Ruby
- **License:** Various open-source licenses

### Secondary: Custom Annotations
- GitHub repositories with labeled issues
- Bug reports and fix commits
- Code smell detection datasets

---

## ðŸ§° Technologies Used

### Machine Learning
- PyTorch / Transformers (Hugging Face)
- CodeBERT, GraphCodeBERT
- TensorBoard for monitoring
- scikit-learn for metrics

### Full-Stack
- **Backend:** FastAPI
- **Frontend:** Streamlit / Gradio
- **Database:** SQLite (for caching)

### Deployment
- Docker / Docker Compose
- Kubernetes (optional)
- AWS / GCP / Azure (cloud deployment)

---

## ðŸ“ Usage Example

```python
from src.deployment.inference import CodeReviewer

# Initialize the model
reviewer = CodeReviewer(model_path="models/best_model.pt")

# Review code
code_snippet = """
def calculate_average(numbers):
    total = 0
    for num in numbers:
        total += num
    return total / len(numbers)
"""

results = reviewer.review(code_snippet)

# Output:
# {
#   "issues": [
#     {
#       "type": "bug",
#       "severity": "high",
#       "message": "Potential ZeroDivisionError if list is empty",
#       "line": 5,
#       "confidence": 0.92
#     },
#     {
#       "type": "style",
#       "severity": "low",
#       "message": "Consider using built-in sum() function",
#       "line": 2-4,
#       "confidence": 0.78
#     }
#   ]
# }
```

---

## ðŸŽ¥ Demo Video

Watch our 10-minute project demo: [presentation/demo-video.mp4](presentation/demo-video.mp4)

**Topics covered:**
- Problem statement and motivation
- Data exploration and preprocessing
- Model architecture and training
- Ablation studies and hyperparameter tuning
- Live application demo
- Deployment pipeline
- Results and future work

---

## ðŸ“„ Final Report

See [docs/FINAL_REPORT.md](docs/FINAL_REPORT.md) for the complete academic report including:
- Introduction and related work
- Data description and preprocessing
- Methodology and model architecture
- Experiments and ablation studies
- Results and visualizations
- Conclusion and future work

---

## ðŸ¤ Contributing

This is an academic project. For questions or collaboration:
- Open an issue on GitHub
- Contact team members via university email

---

## ðŸ“œ License

MIT License - See [LICENSE](LICENSE) file

---

## ðŸ™ Acknowledgments

- **Microsoft Research:** CodeBERT pre-trained model
- **GitHub:** CodeSearchNet dataset
- **Hugging Face:** Transformers library
- **CS 5590 Course Staff:** Guidance and feedback

---

## ðŸ“ž Contact

For questions about this project:
- **Repository:** https://github.com/YOUR_USERNAME/code-review-assistant
- **Course:** CS 5590 - AI/ML and Data Science
- **Semester:** Fall 2024

---

**Built with â¤ï¸ for better code quality**
